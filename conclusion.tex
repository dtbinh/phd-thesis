%1234567890123456789012345678901234567890123456789012345678901234567890123456789
\chapter{Conclusion}

Within this dissertation, we have presented a set of algorithms and frameworks
for developing agile motor skills on virtual and real humanoids.
In this final chapter, we will summarize the proposed techniques and
preliminary results, and suggest future research directions that could provide
the next steps toward more effective systems for real humanoids.

\section{Discussion}
The dissertation started from designing controllers for the specific tasks
such as falling strategies,
and covered a set of general computational tools to develop
various motor skills.
Using the proposed techniques, various motor skills can be intuitively designed
in virtual simulation and easily transferred to physical systems.
Several optimization algorithms were also designed to develop more versatile and
robust physics-based controllers for humanoids within a short amount of time.
Further, various falling scenarios of virtual and real humanoids were
extensively studied to ensure safety of humanoids and to achieve smooth
transitions between motor skills.

Chapter 3 described a method to generate agile falling and landing motions of
virtual characters in real-time via physical simulation
without using motion capture data or pre-scripted animation.
By designing novel controllers based on three landing principles informally
developed in Parkour community, we can develop a robust controller that
allows the character to fall from a wide range of heights and initial speeds,
roll on the ground, and get back on its feet, without inducing large stress on
joints at any moment.

Chapter 4 introduced a new planning algorithm to minimize the damage
of humanoid falls by utilizing multiple contact points.
Instead of selecting among a collection of manually designed control
strategies, we proposed a novel algorithm which plans for appropriate
falling motions to a wide variety of falls.
Our algorithm covers various falling strategies from a single step to recover
from a gentle nudge, to a rolling motion to break a high-speed fall.

The iterative learning framework of Chapter 5 allows users to intuitively
develop dynamic controllers for virtual characters only using high-level,
human-readable instructions.
We introduced control rigs that
formulate an intermediate layer 
for facilitating mapping between high-level instructions and manipulating
multiple low-level control variables.
The control rigs are design for utilizing the human coach's knowledge and 
reducing the search space for control optimization.

The optimization problems formulated in Chapter 5 can be efficiently solved
using a new sampling-based optimization method, Covariance Matrix
Adaptation with Classification (CMA-C), explained in Chapter 6.
Inspired by the human ability to learn from failure,
CMA-C utilizes the failed simulation samples to approximate infeasible regions,
resulting in a faster convergence than the standard CMA-ES.

Chapter 7 shows how to optimize a parameterized motor skill which
is essential for autonomous robots operating in an unpredictable environment.
Our algorithm achieves a faster convergence rate by evolving a parameterized
probability distribution for the entire range of tasks.

The method described in Chapter 8 provides us a framework for reducing hardware
experiments which is usually very time-consuming and costly.
The goal of this method is to learn the difference between simulation and
hardware systems, and optimize a control policy that works on the target system.
Instead of learning the model from scratch, our method learns only the
difference between virtual and real system and reduces
numbers of hardware experiments.

\section{Future work}
This section presents a few interesting future directions for more intuitively
and effectively developing agile motor skills on virtual and real humanoids.
Especially, the proposed techniques are not exhaustively examined on hardware
of humanoids, which may require additional experiments.
%% Although we demonstrated the preliminary results, 
%% the entire pipeline is not exhaustively examined on hardware.
%% This section presents a few interesting future directions for deploying 
%% the proposed techniques on real humnaoids.

\subsection{Realtime controllers for non-planar falls}
In Chapter 4, we presented a falling strategy that breaks a fall by
utilizing multiple contact points to reduce damage to humanoids.
However, the proposed strategy require two major revisions to be deployed 
on real hardware, achieving realtime performance and handling non-planar falls.

\paragraph{Realtime planning of falls.}
Planning of falling motions must be very efficient to provide enough time for
executing planned motions. 
However, the current implementation of the algorithm take a few seconds, which
is far from realtime performance that can be deployed to hardware of robots.
One possible option for acceleration is to precompute falling motions for
varius initial cases in the preprocessing stage.
When we detect a fall from sensors, we can select the optimal falling motion
for the state that is similar to the current instead of computing it at the
realtime.

\paragraph{Planning of non-planar falls.}
Also, our algorithm is limited to planar falling motions.
Although we focus on planar falls in the sagittal plane, most of humanoid falls
accompany all rotations in pitch, yaw, and roll axes.
An intuitive approach for handling non-planar cases is to use a more complex
abstract model, such as an inertia-loaded pendulum, that can account spins in
all directions.
Because the proposed algorithm is not confined to the specific choice of the
abstract model, we can incorporate different abstract models by augumenting
state and action spaces. 
However, the discretization of spaces and computation of dynamic programming
must be improved for efficiency because more dimensions would increase the
computation time tremendously, which is so called a curse of dimensionality. 

\subsection{A more intuitive learning interface}

In Chapter 5, we presented the learning framework for teaching
virtual characters how to execute dynamic motor skills using only high-level
instructions. 
However, the current design of the framework still requires a long and
repetitive sequence of instructions for motions with a large number of target
angles, which is not straightforward for a novice user. 
Therefore, designing a more intuitive interface that can efficiently develop
more complex motions can be an interesting future direction of this
disseration. 

\paragraph{Motion capture systems.}
Extending the framework with motion capture systems may reduce the number of
instructions to describe the motion.
With the motion capture system, a user can simply capture his pose or motion in
front of camera, which can be described by multiple high-level instructions.
However, we would like to note that this suggestion is different from simply
reconstructing the capture motions.
Because there are many differences between a user and a humanoid including body
dimensions and actuator limitations, a user may not
be agile enough to perform the athletic target motion such as a back-filp, or
a humanoid cannot follow the captured motion.

\paragraph{Hierarchical composition of controllers.}
Another technique to prevent the repetition of similar instructions is to
formulate a hierarchical structure of controllers that further extends the
current concept of ``control rigs'' for simultaneously manipulating multiple
low level controllers.
In this concept, we can design a tree structure that a controller has
pre-defined or previously trained controllers as descendants.
For instance, a drop-and-roll motion can be decomposed into a jump, a
transition, and a roll that are previously trained, and
it can be served as another component for the even more complex motions.
This hierarchical structure allows users to describe a motion in higher level
of instructions such as ``jump further'' or ``roll faster'', which is more
similar to the human training process. 
In addition, re-optimizing controllers in this representation can be done much
more efficiently than learning new controllers from scratch, by conducting the
optimization in the reduced parameter space.

\subsection{Dynamics bias learning for humanoids} 

We previously demonstrated a framework for learning dynamic bias
a simple legged robot in Chapter 8, but it is not fully verified on a
full-scale humanoid.
Because humanoid robots usually have much higher degrees of freedom ranging
from 16 to 34 [GP, Atlas, Sarcos], a na\"{\i}ve approach will require
tremendous amount of data which is infeasible to be obtained.
There are several possible approaches for resolving this curse of
dimensionality
%% , such as projecting into a lower dimensional space using a
%% simplified model or adopting active learning to maximize the amount of
%% information from a single hardware experiment.
For instance, a high dimensional parameter space can be projected into a lower
dimensional space using a simplified model, which is a popular approach to
decrease the number of dimensions [Sugimoto]
Another possibility is to employ the concept of active learning.
Instead of executing the current best policy, we can find the most
informative policy that maximizes the amount of data we can get from a
single hardware experiment [da Silva].
Cutler and his colleague [Cutler] proposed to use multiple simulators with
different credibilities to efficient solve reinforcement problems in the
discretized grid setting.
Although the control of humanoid must be able to handle continuous spaces,
optimizing the policy with multiple simulators will give us a chance to obtain
more robust controllers that work for a wider range of scenarios.














