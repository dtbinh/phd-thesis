%1234567890123456789012345678901234567890123456789012345678901234567890123456789
\chapter{Conclusion}

Within this dissertation, we have presented a set of algorithms and frameworks
for developing agile motor skills on virtual and real humanoids.
In this final chapter, we will summarize the proposed techniques and
preliminary results, and suggest future research directions that could provide
the next steps toward more effective systems for real humanoids.

\section{Discussion}
The dissertation started from designing controllers for the specific tasks
such as falling strategies,
and covered a set of general computational tools to develop
various motor skills.
Using the proposed techniques, various motor skills can be intuitively designed
in virtual simulation and easily transferred to physical systems.
Several optimization algorithms were also designed to develop more versatile and
robust physics-based controllers for humanoids within a short amount of time.
Further, various falling scenarios of virtual and real humanoids were
extensively studied to ensure safety of humanoids and to achieve smooth
transitions between motor skills.

Chapter 3 described a method to generate agile falling and landing motions of
virtual characters in real-time via physical simulation
without using motion capture data or pre-scripted animation.
By designing novel controllers based on three landing principles informally
developed in Parkour community, we can develop a robust controller that
allows the character to fall from a wide range of heights and initial speeds,
roll on the ground, and get back on its feet, without inducing large stress on
joints at any moment.

Chapter 4 introduced a new planning algorithm to minimize the damage
of humanoid falls by utilizing multiple contact points.
Instead of selecting among a collection of manually designed control
strategies, we proposed a novel algorithm which plans for appropriate
falling motions to a wide variety of falls.
Our algorithm covers various falling strategies from a single step to recover
from a gentle nudge, to a rolling motion to break a high-speed fall.

The iterative learning framework of Chapter 5 allows users to intuitively
develop dynamic controllers for virtual characters only using high-level,
human-readable instructions.
We introduced control rigs that
formulate an intermediate layer 
for facilitating mapping between high-level instructions and manipulating
multiple low-level control variables.
The control rigs are design for utilizing the human coach's knowledge and 
reducing the search space for control optimization.

The optimization problems formulated in Chapter 5 can be efficiently solved
using a new sampling-based optimization method, Covariance Matrix
Adaptation with Classification (CMA-C), explained in Chapter 6.
Inspired by the human ability to learn from failure,
CMA-C utilizes the failed simulation samples to approximate infeasible regions,
resulting in a faster convergence than the standard CMA-ES.

Chapter 7 shows how to optimize a parameterized motor skill which
is essential for autonomous robots operating in an unpredictable environment.
Our algorithm achieves a faster convergence rate by evolving a parameterized
probability distribution for the entire range of tasks.

The method described in Chapter 8 provides us a framework for reducing hardware
experiments which is usually very time-consuming and costly.
The goal of this method is to learn the difference between simulation and
hardware systems, and optimize a control policy that works on the target system.
Instead of learning the model from scratch, our method learns only the
difference between virtual and real system and reduces
numbers of hardware experiments.

\section{Future work}
This section presents a few interesting future directions for improving the
proposed techniques in this dissertation.
%% Especially, they are not exhaustively examined on hardware
%% of humanoids, which may require additional experiments.

\subsection{Real-time controllers for non-planar falls}
In Chapter 4, we presented a falling strategy that breaks a fall by
utilizing multiple contact points to reduce damage to humanoids.
However, the proposed strategy requires two major revisions to be deployed 
on real robots: achieving real-time performance and handling non-planar falls.

\paragraph{Real-time planning of falls.}
Planning of falling motions must be very efficient to provide enough time for
executing planned motions. 
However, the current implementation of the algorithm takes a few seconds, which
is far from real-time that can be deployed to hardware of robots.
One possible option is to compute falling motions for
various initial cases in the pre-processing stage.
When a fall is predicted, we can simply select the optimal falling motion
that is designed for the closest scenario to the current state,
instead of computing it online.

\paragraph{Planning of non-planar falls.}
%% Our algorithm is limited to planar falling motions.
Although we previously focus on planar falls in the sagittal plane as a proof
of concept for the multiple contact falling strategy, humanoid falls
can accompany all rotations in pitch, yaw, and roll axes.
An intuitive approach for handling non-planar cases is to use a more complex
abstract model, such as an inertia-loaded pendulum, that can account intertia
and momentum in all axes.
Because the proposed algorithm is not confined to the specific choice of the
abstract model, we can easily incorporate different models by
augmenting state and action spaces. 
However, the discretization of spaces and computation of dynamic programming
must be improved for efficiency because more dimensions would increase the
computation time tremendously, which is so called a curse of dimensionality. 

\subsection{A more intuitive learning interface}

In Chapter 5, we presented the learning framework for teaching
virtual characters how to execute dynamic motor skills using only high-level
human-readable instructions. 
However, the current design of the framework still requires a long and
repetitive sequence of instructions for complex motions with a large 
number of target angles, which is not straightforward for novice users. 
Therefore, designing a more intuitive interface that can efficiently develop
more complex motions can be an interesting future direction.

\paragraph{Motion capture systems.}
Extending the framework with motion capture systems may reduce the number of
instructions to describe the motion.
With the motion capture system, a user can simply capture his/her pose or
motion in front of the camera, which can be described by multiple high-level
instructions. 
However, we would like to note that this is different from simply
reconstructing the capture motions.
In motion reconstruction, a user may not be agile enough to perform
the athletic target motion such as a back-flip,
or the captured motion cannot be executed by humanoids due to differences
between a user and a humanoid including body dimensions or joint structures.

\paragraph{Hierarchical composition of controllers.}
Another technique to prevent the repetition of similar instructions is to
formulate a hierarchical structure of controllers that further extends the
current concept of ``control rigs'' that simultaneously manipulates multiple
low level controllers.
In this concept, we can design a tree structure that a controller recursively
has pre-defined or previously trained controllers as descendants.
For instance, a drop-and-roll motion can be decomposed into a jump, a
transition, and a roll that are previously trained, and
it can be served as another component for a even more complex motion.
This hierarchical structure allows users to describe a motion in higher level
of instructions such as ``jump further'' or ``roll faster''.
%% , which is more
%% similar to the human training process than the pre-defined instructions.
In addition, re-optimizing controllers in this representation can be done much
more efficiently than learning new controllers from scratch, by conducting the
optimization in the reduced parameter space.

\subsection{Dynamics bias learning for humanoids} 

We previously demonstrated a framework for learning dynamic bias
a simple legged robot in Chapter 8, but it is not fully verified on a
full-scale humanoid.
Because humanoid robots usually have much higher degrees of freedom than simple
robots, 
a na\"{\i}ve approach will require
a tremendous amount of data which is infeasible to be obtained.
There are several possible approaches for resolving this issue.
%% , such as projecting into a lower dimensional space using a
%% simplified model or adopting active learning to maximize the amount of
%% information from a single hardware experiment.
For instance, a high dimensional parameter space can be projected into a lower
dimensional space using a simplified model, which is a popular approach to
decrease the number of dimensions \cite{bib-humanoid13-trajectory}.
Another possibility is to employ the concept of active learning.
Instead of executing the current best policy, we can find the most
informative policy that maximizes the amount of data we can get from a
single hardware experiment \cite{DaSilva:2014:ACP}.
In addition, we can use multiple simulators as the work of Cutler and his
colleagues \cite{bib-icra14-reinforcement} that efficient solves reinforcement
problems in the discretized grid setting. 
%% Finally, Cutler and his colleague \cite{bib-icra14-reinforcement} proposed to
%% use multiple simulators to efficient solve reinforcement problems in the
%% discretized grid setting.
%% Although the control of humanoid requires to handle continuous spaces,
Although it is required to extend the approach for continuous spaces,
optimizing the policy with multiple simulators will give us a chance to obtain
more robust controllers that work for a wider range of scenarios.














